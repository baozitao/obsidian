1. 想要将深度学习应用于小型图像数据集，一种常用且非常高效的方法是使用**预训练网络**。预训练网络（pretrained network）是一个保存好的网络，**之前已在大型数据集（通常是大规模图像分类任务）上训练好**。如果这个**原始数据集足够大且足够通用**，**那么预训练网络学到的特征的空间层次结构可以有效地作为视觉世界的通用模型**，因此这些特征可用于各**种不同的计算机视觉问题**，即使**这些新问题涉及的类别和原始任务完全不同**。举个例子，你在 ImageNet 上训练了一个网络（其类别主要是动物和日常用品），然后将这个训练好的网络应用于某个不相干的任务，比如在图像中识别家具。**这种学到的特征在不同问题之间的可移植性**，是深度学习与许多早期浅层学习方法相比的重要优势，它使得深度学习对小数据问题非常有效。
2. 某个卷积层提取的表示的通用性（以及可复用性）**取决于该层在模型中的深度**。模型中更靠近**底部的层提取的是局部的、高度通用的特征图**（比如视觉边缘、颜色和纹理），而更靠近**顶部的层提取的是更加抽象的概念**（比如“猫耳朵”或“狗眼睛”）。因此，如果你的新数据集与原始模型训练的数据集有很大差异，那么最好只使用模型的前几层来做特征提取，而不是使用整个卷积基。