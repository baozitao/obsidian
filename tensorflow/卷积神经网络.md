1. 卷积神经网络学到的模式具有**平移不变性**（translation invariant）。卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。对于密集连接网络来说，如果模式出现在新的位置，它只能重新学习这个模式。这使得卷积神经网络在处理图像时可以高效利用数据（因为**视觉世界从根本上具有平移不变性**），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。
2. 卷积神经网络可以学到**模式的空间层次结构**（spatial hierarchies of patterns），见图 5-2。**第一个卷积层将学习较小的局部模式（比如边缘）**，**第二个卷积层将学习由第一层特征组成的更大的模式**，以此类推。这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念（因为视觉世界从根本上具有空间层次结构）。
3. 我们刚刚揭示了深度神经网络学到的表示的一个重要普遍特征：**随着层数的加深，层所提取的特征变得越来越抽象**。**更高的层激活包含关于特定输入的信息越来越少，而关于目标的信息越来越多（本例中即图像的类别：猫或狗）**。深度神经网络可以有效地作为信息蒸馏管道（information distillation pipeline），输入原始数据（本例中是 RGB 图像），反复对其进行变换，将无关信息过滤掉（比如图像的具体外观），并放大和细化有用的信息（比如图像的类别）。
4. 这与人类和动物感知世界的方式类似：人类观察一个场景几秒钟后，可以记住其中有哪些抽象物体（比如自行车、树），但记不住这些物体的具体外观。事实上，**如果你试着凭记忆画一辆普通自行车，那么很可能完全画不出真实的样子，虽然你一生中见过上千辆自行车**（见图 5-28）。你可以现在就试着画一下，这个说法绝对是真实的。**你的大脑已经学会将视觉输入完全抽象化，即将其转换为更高层次的视觉概念，同时过滤掉不相关的视觉细节，这使得大脑很难记住周围事物的外观**。
